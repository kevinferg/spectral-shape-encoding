{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04473751",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "\n",
    "from data_loading import *\n",
    "from pytorch_utils import *\n",
    "from models import *\n",
    "from evaluation import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac00a60",
   "metadata": {},
   "source": [
    "### Load datasets\n",
    "\n",
    "- 6 within-sample-set datasets: stored in `wss_data` dictionary - key names in `data_names`\n",
    "- 6 out-of-sample-set datasets: stored in `oss_data` dictionary - key names in `data_names`\n",
    "- Load from datasets in `data/` directory\n",
    "- Also get train/test indices for each. These are in `i_tr` and `i_val` dictionaries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff18263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_names = [\"vor\",\"lat\",\"both\"]\n",
    "stress_names = [\"stress_\" + shape for shape in shape_names]\n",
    "temp_names = [\"temp_\" + shape for shape in shape_names]\n",
    "data_names = stress_names + temp_names\n",
    "\n",
    "wss_data = dict()\n",
    "oss_data = dict()\n",
    "i_tr = dict()\n",
    "i_val = dict()\n",
    "datadir = \"data/\"\n",
    "\n",
    "for name in data_names:\n",
    "    if name == \"stress_both\":\n",
    "        wss_data[name] = wss_data[\"stress_vor\"] + wss_data[\"stress_lat\"]\n",
    "        oss_data[name] = oss_data[\"stress_vor\"] + oss_data[\"stress_lat\"]\n",
    "    \n",
    "    elif name == \"temp_both\":\n",
    "        wss_data[name] = wss_data[\"temp_vor\"] + wss_data[\"temp_lat\"]\n",
    "        oss_data[name] = oss_data[\"temp_vor\"] + oss_data[\"temp_lat\"]\n",
    "    \n",
    "    else:\n",
    "        scale = 1. if \"temp\" in name else 10000.   # Divide stress values by 10000Pa\n",
    "        wss_data[name] = load_matlab_dataset(datadir + name + \"_w.mat\", scale)\n",
    "        oss_data[name] = load_matlab_dataset(datadir + name + \"_o.mat\", scale)\n",
    "    \n",
    "    idxs_tr, idxs_val = get_split_indices(wss_data[name])\n",
    "    \n",
    "    i_tr[name] = idxs_tr\n",
    "    i_val[name] = idxs_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daa4711",
   "metadata": {},
   "source": [
    "## Models\n",
    "### Create models\n",
    "\n",
    "- 6 `SSENet` models, one per dataset: `models` dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ed3723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = dict()\n",
    "for name in data_names:\n",
    "    model = SSENet()\n",
    "    models[name] = model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d28ac0d",
   "metadata": {},
   "source": [
    "## Train models\n",
    "\n",
    "- Train each model for 50 epochs with learning rate 0.001\n",
    "- Store loss curves in `hist_tr` (training) and `hist_val` (validation)\n",
    "- Store training times in `times`\n",
    "- Save models as .pth files in this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6757e15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_tr = dict()\n",
    "hist_val = dict()\n",
    "times = dict()\n",
    "\n",
    "for name in data_names:\n",
    "    print(f\"\\n\\n_________________________ Now Training: {name} _________________________\")\n",
    "    model = models[name]\n",
    "    dataset = wss_data[name]\n",
    "    idxs_tr, idxs_val = i_tr[name], i_val[name]\n",
    "    model, tr_loss, val_loss, train_time = train_model(model, dataset, idxs_tr, idxs_val)\n",
    "    \n",
    "    models[name] = model\n",
    "    hist_tr[name] = tr_loss\n",
    "    hist_val[name] = val_loss\n",
    "    times[name] = train_time\n",
    "    torch.save(model, \"model_\" + name + \".pth\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce35c4d",
   "metadata": {},
   "source": [
    "### Plot loss\n",
    "\n",
    "- Plot loss for stress prediction models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb71690",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = dict(stress_lat = \"Lattice Set\", stress_vor = \"Voronoi Set\", stress_both = \"Combined Set\" )\n",
    "\n",
    "\n",
    "plt.figure(dpi=120, figsize=(5,3))\n",
    "\n",
    "for name in stress_names:\n",
    "    plt.plot(hist_val[name],\"--\",label = label_names[name] + \": Validation\")\n",
    "    plt.plot(hist_tr[name], \"-\", label = label_names[name] + \": Training\")\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "#plt.savefig('stress_loss.png',bbox_inches = \"tight\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9081053c",
   "metadata": {},
   "source": [
    "### Evaluate models\n",
    "\n",
    "- Compute $R^2$ values for all models\n",
    "- Save all distributions to `r2s_tr` (training), `r2s_te` (testing), and `rts_oss` (outside sample set)\n",
    "- Display median values for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913511b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "r2s_tr  = dict()\n",
    "r2s_te  = dict()\n",
    "r2s_oss = dict()\n",
    "\n",
    "\n",
    "for name in data_names:\n",
    "    model = models[name]\n",
    "    wss = wss_data[name]\n",
    "    oss = oss_data[name]\n",
    "    idxs_tr, idxs_val = i_tr[name], i_val[name]\n",
    "    \n",
    "    vals1, vals2, vals3 = evaluate_all_data(model, wss, idxs_tr, idxs_val, oss)\n",
    "    r2s_tr[name]  = vals1\n",
    "    r2s_te[name]  = vals2\n",
    "    r2s_oss[name] = vals3\n",
    "    print(f\"Model: {name}\")\n",
    "    print(\"Train Median: %0.4f    Test Median: %0.4f    OSS Median: %0.4f\\n\" \n",
    "        %(    np.median(vals1),     np.median(vals2),    np.median(vals3)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5aa498",
   "metadata": {},
   "source": [
    "### Plot $R^2$ distributions\n",
    "\n",
    "- Using the model trained on Combined Set for stress prediction, `models[\"stress_both\"]`\n",
    "- Display boxplot distribution of $R^2$ for training, testing, and out-of-sample sets\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87082a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"stress_both\"\n",
    "model = models[name]\n",
    "wss = wss_data[name]\n",
    "oss = oss_data[name]\n",
    "idxs_tr, idxs_val = i_tr[name], i_val[name]\n",
    "\n",
    "vals1, vals2, vals3 = evaluate_all_data(model, wss, idxs_tr, idxs_val, oss)\n",
    "plot_boxes(vals1,vals2,vals3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90ee891",
   "metadata": {},
   "source": [
    "### Train partial models\n",
    "\n",
    "#### Train models with the following input combinations:\n",
    "\n",
    "|  (x, y, SDF) | Local features   | Global features |\n",
    "|  :-:         | :-:              | :-:             |\n",
    "| $\\checkmark$ | -                | $\\checkmark$    |\n",
    "| $\\checkmark$ | $\\checkmark$     |  -              |\n",
    "| -            | $\\checkmark$     | $\\checkmark$    |\n",
    "\n",
    "- Models use `SSENetCustom()` to get access to partial inputs\n",
    "- Train for Combined Set stress data only\n",
    "- Save models in this directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358d87ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_names = [\"xyd_global\",\"xyd_local\",\"local_global\"]\n",
    "partials = [(1,0,1),(1,1,0),(0,1,1)]\n",
    "partial_models = []\n",
    "name = \"stress_both\"\n",
    "dataset = wss_data[name]\n",
    "idxs_tr, idxs_val = i_tr[name], i_val[name]\n",
    "\n",
    "for i, p in enumerate(partials):\n",
    "    model = SSENetCustom(p)\n",
    "    model, tr_loss, val_loss, train_time = train_model(model, dataset, idxs_tr, idxs_val)\n",
    "    partial_models.append(model)\n",
    "    model_name = \"model_\" + partial_names[i] + \".pth\"\n",
    "    torch.save(model, model_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "097eb4d5",
   "metadata": {},
   "source": [
    "### Evaluate partial models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8280352",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"stress_both\"\n",
    "wss = wss_data[name]\n",
    "oss = oss_data[name]\n",
    "idxs_tr, idxs_val = i_tr[name], i_val[name]\n",
    "\n",
    "for i in enumerate(partial_names):\n",
    "    model = partial_models[i]\n",
    "    vals1, vals2, vals3 = evaluate_all_data(model, wss, idxs_tr, idxs_val, oss)\n",
    "\n",
    "    print(f\"Model: {partial_names[i]}\")\n",
    "    print(\"Train Median: %0.4f    Test Median: %0.4f    OSS Median: %0.4f\\n\" \n",
    "        %(    np.median(vals1),     np.median(vals2),    np.median(vals3)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
